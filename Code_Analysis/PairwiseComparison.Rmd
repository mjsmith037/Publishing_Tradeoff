---
title: 'Pairwise Correlation Analysis for:'
subtitle: '"And, not Or: Quantity, Quality in Scientific Publishing"'
author: 'Matthew J. Michalska-Smith & Stefano Allesina'
output: 
  html_document: 
    highlight: pygments
---

## Import libraries
```{r, message=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
```

## Global parameters
```{r}
INTERVAL_START <- 1991  # oldest papers to be included in the analysis
INTERVAL_END <- 2010    # most recent papers to be included
MINPAPERS <- 20         # minimum paper cutoff for authors to be considered
```

## Functions
```{r}
## This function takes in a dataframe containing the publication record for an
## author (produced by `Retreive_papers.py`) and the size of the sliding window
## for comparison and calculates the percentage of all possible pairs that are
## concordant
get_concordance <- function(dat, nyears) {
    ## get all possible pairings
    combn(dat$PaperID, 2) %>%
        ## restructuring to facilitate analysis
        t() %>% tbl_df() %>%
        left_join(dat, by=c(V1="PaperID")) %>%
        left_join(dat, by=c(V2="PaperID")) %>%
        ## filter out the pairs that have the same productivity (will not affect
        ## concordance calculation) or are across a timespan greater than the
        ## sliding window
        filter(productivity.x != productivity.y,
               abs(Year.x - Year.y) <= nyears) %>%
        ## calculate percent concordance
        summarise(sum(((Citations.x > Citations.y) & (productivity.x > productivity.y)) |
                          ((Citations.x < Citations.y) & (productivity.x < productivity.y))) /
                      n()) %>%
        ## return as numeric vector
        as.numeric()
}
```

```{r}
## This function reads in the publication record for a given individual, measures
## the productivty, and performs the pairwise correlation analysis. As input,
## this function takes the name of the file containing the publication record,
## whether or not to analyze pairs of papers or pairs of summary statistics by
## year, the size of the sliding window, and whether or not to randomize the
## citation counts prior to analysis
pairwise_correlation <- function(fname, summary_stats=FALSE, nyears=Inf, randomize=FALSE){
    ## read in the publication record generated by `Retrieve_papers.py`
    papers <- read.csv(fname, sep = ";", quote="%", stringsAsFactors=FALSE) %>%
        ## filter out papers outside of interval considered in the analysis
        filter(Year >= INTERVAL_START, Year <= INTERVAL_END, PaperID != "")
    ## if insufficient records, skip
    if (nrow(papers) <= MINPAPERS) return(NULL)
    ## scramble the citation counts if desired
    if (randomize) papers$Citations <- sample(papers$Citations)
    ## Measure productivity (number of papers published) in a given year
    productivity <- papers %>%
        group_by(Year) %>%
        summarise(productivity = n()) %>%
        ungroup()
    ## Add the productivity to the publication record
    papers <- inner_join(papers, productivity, by="Year")
    ## if only one unique productivity (author publishes exactly the same number
    ## of papers each year), skip
    if (length(unique(papers$productivity)) < 2) return(NULL)
    ## if comparing summary statistics of yearly citation count distributions
    if (summary_stats) {
        ## only look at the mean/median/best/worst paper in each year
        papers <- papers %>%
            group_by(Author, Year) %>%
            summarise(mean_cits = mean(Citations),
                      med_cits = median(Citations),
                      min_cits = min(Citations),
                      max_cits = max(Citations)) %>%
            ungroup() %>%
            gather("variable", "Citations", mean_cits, med_cits, min_cits, max_cits) %>%
            ## and add these values back into the publication record
            left_join(papers %>% select(Author, Year, productivity, Citations, PaperID),
                      by=c("Author", "Year", "Citations")) %>%
            ## removing duplicates
            distinct(Author, Year, variable, Citations, productivity, .keep_all=TRUE)
        ## because the median and mean paper in each year are hypotheticals (they do not
        ## necessarily correspond to an actual paper published in that year), we have to add
        ## in the productivities manually and assign PaperIDs to get concordance
        papers$productivity[is.na(papers$productivity)] <- productivity %>%
            right_join(papers %>%
                           filter(is.na(productivity)) %>%
                           select(Author, Year), by="Year") %>%
            .$productivity
        if (length(papers$PaperID[is.na(papers$PaperID)]) > 0) {
            ## create PaperIDs that are just incrementing integers
            papers$PaperID[is.na(papers$PaperID)] <- 1:sum(is.na(papers$PaperID))
        }
        ## combine the results for each summary statistic
        concordance_df <- bind_rows(
            tibble(author=str_extract(fname, "\\d+"),
                   concordance=get_concordance(papers %>% filter(variable=="mean_cits"),
                                               nyears),
                   sum_stat="Mean Paper / Year",
                   nyears,
                   rand=randomize),
            tibble(author=str_extract(fname, "\\d+"),
                   concordance=get_concordance(papers %>% filter(variable=="med_cits"),
                                               nyears),
                   sum_stat="Median Paper / Year",
                   nyears,
                   rand=randomize),
            tibble(author=str_extract(fname, "\\d+"),
                   concordance=get_concordance(papers %>% filter(variable=="min_cits"),
                                               nyears),
                   sum_stat="Minimum Paper / Year",
                   nyears,
                   rand=randomize),
            tibble(author=str_extract(fname, "\\d+"),
                   concordance=get_concordance(papers %>% filter(variable=="max_cits"),
                                               nyears),
                   sum_stat="Maximum Paper / Year",
                   nyears,
                   rand=randomize)
        )
    } else {
        ## if not considering the summary statistics, then look at all pairs of papers
        ## between years with different productivities
        concordance_df <- tibble(author=str_extract(fname, "\\d+"),
                                 concordance=get_concordance(papers, nyears),
                                 sum_stat="All Pairs",
                                 nyears,
                                 rand=randomize)
    }
    return(concordance_df)
}
```


```{r}
## this function runs the analysis for a range of sliding window sizes
run_pairwise_comparison <- function() {
    results <- tibble()
    for (ny in c(1:5, Inf)) {
        ## run each sliding window for each publication record in the `../data` folder
        for (ff in Sys.glob("../Data/*.csv")){
            ## compile the results into a single tbl_df
            results <- results %>% bind_rows(pairwise_correlation(ff, summary_stats=TRUE,
                                                                  nyears=ny, randomize=FALSE),
                                             pairwise_correlation(ff, summary_stats=TRUE,
                                                                  nyears=ny, randomize=TRUE),
                                             pairwise_correlation(ff, summary_stats=FALSE,
                                                                  nyears=ny, randomize=FALSE),
                                             pairwise_correlation(ff, summary_stats=FALSE,
                                                                  nyears=ny, randomize=TRUE))
        }
    }
    ## and save the results
    save(results, file=paste0("../Figures/PairwiseComparison_",
                              INTERVAL_START, "-", INTERVAL_END, ".RData")
    )
}
```

## To run analysis:
```{r}
run_pairwise_comparison()
```